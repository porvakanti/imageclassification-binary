{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the images dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = 'images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the directory structure for the algorithm\n",
    "train_dest1 = 'MLU_MPC_Data_With_Dropout/training_set/Class0'\n",
    "train_dest2 = 'MLU_MPC_Data_With_Dropout/training_set/Class1'\n",
    "valid_dest1 = 'MLU_MPC_Data_With_Dropout/validation_set/Class0'\n",
    "valid_dest2 = 'MLU_MPC_Data_With_Dropout/validation_set/Class1'\n",
    "test_dest1 = 'MLU_MPC_Data_With_Dropout/test_set/Class0'\n",
    "test_dest2 = 'MLU_MPC_Data_With_Dropout/test_set/Class1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Load the csv file that lists the image id's and their respective labels that can be used for training and validation\n",
    "training_original_df = pd.read_csv('training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the csv file that lists the image id's only for the test data set\n",
    "test_df = pd.read_csv('public_test_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagefiles = os.listdir(source) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_original_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train, img_valid = train_test_split(training_original_df, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the training image set to its corresponding folder structure\n",
    "for index, row in img_train.iterrows():\n",
    "    imgid = row['ID']\n",
    "    imgclass = row['class']\n",
    "    filename = str(imgid)+'.png'\n",
    "    for f in imagefiles:\n",
    "        if f == filename:\n",
    "            if imgclass == 0:\n",
    "                shutil.copy(source+'/'+f,train_dest1)\n",
    "            elif imgclass == 1:\n",
    "                shutil.copy(source+'/'+f,train_dest2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the validation image set to its corresponding folder structure\n",
    "for index, row in img_valid.iterrows():\n",
    "    imgvid = row['ID']\n",
    "    imgvclass = row['class']\n",
    "    filenamev = str(imgvid)+'.png'\n",
    "    for fv in imagefiles:\n",
    "        if fv == filenamev:\n",
    "            if imgvclass == 0:\n",
    "                shutil.copy(source+'/'+fv,valid_dest1)\n",
    "            elif imgvclass == 1:\n",
    "                shutil.copy(source+'/'+fv,valid_dest2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\porvakan\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the network\n",
    "\n",
    "classifier = Sequential()\n",
    "classifier.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape = (64, 64, 3)))\n",
    "classifier.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "classifier.add(Dropout(0.25))\n",
    " \n",
    "classifier.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "classifier.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "classifier.add(Dropout(0.25))\n",
    " \n",
    "classifier.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "classifier.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "classifier.add(Dropout(0.25))\n",
    "\n",
    "classifier.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "classifier.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "classifier.add(Dropout(0.25))\n",
    "\n",
    " \n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dense(units = 256, activation = 'relu'))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 62, 62, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 31, 31, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 29, 29, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 6, 6, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 279,329\n",
      "Trainable params: 279,329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Visualize the network\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2 - Fitting the CNN to the images\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train and test data generators\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "width_shift_range=0.1,\n",
    "height_shift_range=0.1,\n",
    "horizontal_flip = True,\n",
    "vertical_flip=False)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7519 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('MLU_MPC_Data_With_Dropout/training_set',\n",
    "target_size = (64, 64),\n",
    "batch_size = 32,\n",
    "class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2507 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory('MLU_MPC_Data_With_Dropout/validation_set',\n",
    "target_size = (64, 64),\n",
    "batch_size = 32,\n",
    "class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "7519/7519 [==============================] - 10831s 1s/step - loss: 0.3624 - acc: 0.8466 - val_loss: 0.2913 - val_acc: 0.8822\n",
      "Epoch 2/25\n",
      "7519/7519 [==============================] - 10784s 1s/step - loss: 0.2661 - acc: 0.8979 - val_loss: 0.3716 - val_acc: 0.8006\n",
      "Epoch 3/25\n",
      "7519/7519 [==============================] - 10830s 1s/step - loss: 0.2319 - acc: 0.9113 - val_loss: 0.2944 - val_acc: 0.8816\n",
      "Epoch 4/25\n",
      "7519/7519 [==============================] - 11226s 1s/step - loss: 0.2114 - acc: 0.9198 - val_loss: 0.2789 - val_acc: 0.9068\n",
      "Epoch 5/25\n",
      "7519/7519 [==============================] - 11421s 2s/step - loss: 0.1977 - acc: 0.9262 - val_loss: 0.2921 - val_acc: 0.8982\n",
      "Epoch 6/25\n",
      "7519/7519 [==============================] - 11664s 2s/step - loss: 0.1899 - acc: 0.9298 - val_loss: 0.2811 - val_acc: 0.9003\n",
      "Epoch 7/25\n",
      "7519/7519 [==============================] - 11151s 1s/step - loss: 0.1839 - acc: 0.9323 - val_loss: 0.2891 - val_acc: 0.8975\n",
      "Epoch 8/25\n",
      "7519/7519 [==============================] - 10855s 1s/step - loss: 0.1741 - acc: 0.9361 - val_loss: 0.3072 - val_acc: 0.9070\n",
      "Epoch 9/25\n",
      "7519/7519 [==============================] - 10480s 1s/step - loss: 0.1700 - acc: 0.9375 - val_loss: 0.3027 - val_acc: 0.9134\n",
      "Epoch 10/25\n",
      "7519/7519 [==============================] - 10507s 1s/step - loss: 0.1714 - acc: 0.9372 - val_loss: 0.3502 - val_acc: 0.8816\n",
      "Epoch 11/25\n",
      "7519/7519 [==============================] - 10558s 1s/step - loss: 0.1677 - acc: 0.9389 - val_loss: 0.2998 - val_acc: 0.9050\n",
      "Epoch 12/25\n",
      "7519/7519 [==============================] - 11047s 1s/step - loss: 0.1606 - acc: 0.9415 - val_loss: 0.3865 - val_acc: 0.9040\n",
      "Epoch 13/25\n",
      "7519/7519 [==============================] - 10869s 1s/step - loss: 0.1626 - acc: 0.9416 - val_loss: 0.2837 - val_acc: 0.8942\n",
      "Epoch 14/25\n",
      "7519/7519 [==============================] - 10945s 1s/step - loss: 0.1601 - acc: 0.9424 - val_loss: 0.3404 - val_acc: 0.9046\n",
      "Epoch 15/25\n",
      "7519/7519 [==============================] - 10990s 1s/step - loss: 0.1576 - acc: 0.9429 - val_loss: 0.3623 - val_acc: 0.8999\n",
      "Epoch 16/25\n",
      "7519/7519 [==============================] - 11057s 1s/step - loss: 0.1571 - acc: 0.9435 - val_loss: 0.3306 - val_acc: 0.9063\n",
      "Epoch 17/25\n",
      "7519/7519 [==============================] - 11146s 1s/step - loss: 0.1576 - acc: 0.9431 - val_loss: 0.3730 - val_acc: 0.8907\n",
      "Epoch 18/25\n",
      "7519/7519 [==============================] - 11096s 1s/step - loss: 0.1564 - acc: 0.9437 - val_loss: 0.3293 - val_acc: 0.9082\n",
      "Epoch 19/25\n",
      "7519/7519 [==============================] - 11168s 1s/step - loss: 0.1564 - acc: 0.9446 - val_loss: 0.3569 - val_acc: 0.9079\n",
      "Epoch 20/25\n",
      "7519/7519 [==============================] - 11302s 2s/step - loss: 0.1561 - acc: 0.9445 - val_loss: 0.3661 - val_acc: 0.9078\n",
      "Epoch 21/25\n",
      "7519/7519 [==============================] - 11149s 1s/step - loss: 0.1510 - acc: 0.9461 - val_loss: 0.3718 - val_acc: 0.9052\n",
      "Epoch 22/25\n",
      "7519/7519 [==============================] - 11321s 2s/step - loss: 0.1605 - acc: 0.9436 - val_loss: 0.3074 - val_acc: 0.9094\n",
      "Epoch 23/25\n",
      "7519/7519 [==============================] - 11271s 1s/step - loss: 0.1611 - acc: 0.9423 - val_loss: 0.3696 - val_acc: 0.9048\n",
      "Epoch 24/25\n",
      "7519/7519 [==============================] - 11262s 1s/step - loss: 0.1564 - acc: 0.9450 - val_loss: 0.4906 - val_acc: 0.8995\n",
      "Epoch 25/25\n",
      "7519/7519 [==============================] - 11231s 1s/step - loss: 0.1621 - acc: 0.9432 - val_loss: 0.3570 - val_acc: 0.9103\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14bdc1f2e48>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(training_set,\n",
    "steps_per_epoch = 7519,\n",
    "epochs = 25,\n",
    "validation_data = test_set,\n",
    "validation_steps = 2507)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-28\n"
     ]
    }
   ],
   "source": [
    "# Save/Load the model\n",
    "import datetime\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "curdate = now.strftime(\"%Y-%m-%d\")\n",
    "print(curdate)\n",
    "#  %H:%M\n",
    "classifier.save(\"CNN-Classifier-Dropout\"+curdate+\".h5\")\n",
    "#classifier.load(\"file_name.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the submission file\n",
    "submission_file = \"submission6_porvakan.csv\"\n",
    "subcsv = open(submission_file, \"w\", newline='')\n",
    "subcolumnTitleRow = \"ID,class\\n\"\n",
    "subcsv.write(subcolumnTitleRow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the class for each individual image in the test data set\n",
    "test_df = pd.read_csv('public_test_features.csv')\n",
    "\n",
    "for index, row in test_df.iterrows():\n",
    "    img_id = row['ID']\n",
    "    sub_test_image = image.load_img('images/'+str(img_id)+'.png', target_size = (64, 64))\n",
    "    sub_test_image = image.img_to_array(sub_test_image)\n",
    "    sub_test_image = np.expand_dims(sub_test_image, axis = 0)\n",
    "    #sub_test_image = final_datagen.flow(sub_test_image, batch_size=1)\n",
    "    subresult = classifier.predict(sub_test_image)\n",
    "    #training_set.class_indices\n",
    "    subImageID = img_id\n",
    "    subClass = int(subresult[0][0])\n",
    "    subrow = str(subImageID) + \",\" + str(subClass) + \"\\n\"\n",
    "    subcsv.write(subrow)\n",
    "subcsv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
